{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "sys.path.insert(1, \"/home/eecs/wooders/experiments/stl/offline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df714c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init()\n",
    "results_dir = run.use_artifact('ucb-ralf/stl/results:v11', type='dataset').download()\n",
    "orig_results_dir = run.use_artifact('ucb-ralf/stl/results:v4', type='dataset').download()\n",
    "yahoo_train_dir = run.use_artifact('ucb-ralf/stl/yahoo_train_data:v0', type='dataset').download()\n",
    "yahoo_eval_dir = run.use_artifact('ucb-ralf/stl/yahoo_eval_data:v0', type='dataset').download()\n",
    "oracle_dir = run.use_artifact('ucb-ralf/stl/oracle:v0', type='dataset').download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8aea6",
   "metadata": {},
   "source": [
    "# Check Train / Eval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eedb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f\"{yahoo_train_dir}/{key}.csv\")\n",
    "plt.plot(np.arange(len(df_train)), df_train[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(f\"{yahoo_eval_dir}/{key}.csv\")\n",
    "plt.plot(np.arange(len(df_eval)), df_eval[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c30d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train[\"value\"], df_eval[\"value\"]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a15c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(df_train) + len(df_eval)), df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90d110",
   "metadata": {},
   "source": [
    "# Cost Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da276847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use simon's original results \n",
    "orig_results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecde25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import mean_squared_scaled_error\n",
    "def get_loss_per_key(path, oracle_filename):\n",
    "\n",
    "    oracle_residual = pd.read_csv(oracle_filename)[\n",
    "        \"pred_residual\"\n",
    "    ]\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    residual = df[\"pred_residual\"]\n",
    "    mask = ~np.isnan(residual)\n",
    "    loss = mean_squared_scaled_error(\n",
    "        y_true=oracle_residual[mask], y_pred=residual[mask], y_train=df[\"value\"]\n",
    "    )\n",
    "    loss = {\n",
    "        \"loss\": loss,\n",
    "        \"n_fits\": df[\"model_version\"].dropna().nunique(),\n",
    "    }\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274570af",
   "metadata": {},
   "source": [
    "Get baseline results (single key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21099224",
   "metadata": {},
   "outputs": [],
   "source": [
    "replica = 1\n",
    "slides = [6, 12, 18, 24, 48, 96, 168, 192, 336, 672]\n",
    "baseline_results = {}\n",
    "for key in range(1, 101, 1):\n",
    "    \n",
    "    baseline_results[key] = []\n",
    "    \n",
    "    for slide in slides: \n",
    "        oracle_filename = f\"{orig_results_dir}/plan_eval/oracle_key_A4Benchmark-TS{key}.csv\"\n",
    "        baseline_filename = f\"{orig_results_dir}/plan_eval/slide_{slide}_key_A4Benchmark-TS{key}.csv\"\n",
    "\n",
    "        losses = get_loss_per_key(baseline_filename, oracle_filename)\n",
    "        losses[\"slide_size\"] = slide\n",
    "        baseline_results[key].append(losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c2ddd",
   "metadata": {},
   "source": [
    "## Compare to LP Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656758ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [(\"max_fits_1100\", 96), (\"max_fits_2100\", 48), (\"max_fits_4200\", 24), (\"max_fits_8400\", 12)]\n",
    "\n",
    "graph_results = {\"baseline\": [], \"optimized\": [], \"cost\": []}\n",
    "\n",
    "replica = 1\n",
    "for plan, slide_size in experiments:\n",
    "    print(plan, slide_size)\n",
    "    \n",
    "    baseline_total_cost = 0\n",
    "    baseline_total_loss = 0\n",
    "    for key in baseline_results.keys(): \n",
    "        for loss in baseline_results[key]:\n",
    "            if loss['slide_size'] == slide_size:\n",
    "                baseline_total_cost += loss['n_fits']\n",
    "                baseline_total_loss += loss['loss']\n",
    "    print(\"baseline\", baseline_total_cost, baseline_total_loss)\n",
    "    \n",
    "    for key in range(1, 101, 1):\n",
    "        oracle_filename = f\"{orig_results_dir}/plan_eval/oracle_key_A4Benchmark-TS{key}.csv\"\n",
    "        filename = f\"{artifact_dir}/lp_plan_eval/{plan}/{key}.csv\"\n",
    "        lp_results[key] = get_loss_per_key(filename, oracle_filename)\n",
    "        \n",
    "    lp_total_cost = 0\n",
    "    lp_total_loss = 0\n",
    "    for key in lp_results.keys(): \n",
    "        lp_total_cost += lp_results[key]['n_fits']\n",
    "        lp_total_loss += lp_results[key]['loss']\n",
    "    print(\"lp\", lp_total_cost, lp_total_loss)\n",
    "    \n",
    "    assert lp_total_cost <= baseline_total_cost\n",
    "    \n",
    "    graph_results[\"baseline\"].append(baseline_total_loss)\n",
    "    graph_results[\"optimized\"].append(lp_total_loss)\n",
    "    graph_results[\"cost\"].append(baseline_total_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bd58c",
   "metadata": {},
   "source": [
    "## Plot Cost (num fits) + Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "x = 'Factor'\n",
    "\n",
    "df = pd.DataFrame({\n",
    "     x: graph_results[\"cost\"], \n",
    "    'baseline': graph_results[\"baseline\"], \n",
    "    \"optimized\": graph_results[\"optimized\"],\n",
    "})\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "tidy = df.melt(id_vars=x).rename(columns=str.title)\n",
    "seaborn.barplot(x=x, y='Value', hue='Variable', data=tidy, ax=ax1)\n",
    "seaborn.despine(fig)\n",
    "\n",
    "ax1.set(xlabel=\"Cost Budget\", ylabel=f'MASE Loss', title='Residual Estimate Loss for Time-Series Decomposition')\n",
    "#ax1.legend_.remove()\n",
    "#plt.legend(loc='lower center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e429ec",
   "metadata": {},
   "source": [
    "# Plot different numbers of replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use new results dir\n",
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [(\"max_fits_1100\", 96), (\"max_fits_2100\", 48), (\"max_fits_4200\", 24), (\"max_fits_8400\", 12)]\n",
    "replicas = [1, 2]\n",
    "slides = [1, 6, 12, 18, 24, 48, 96, 168, 192, 336, 672]\n",
    "graph_results = {\"baseline\": [], \"optimized\": [], \"cost\": []}\n",
    "prio = \"lifo\"\n",
    "baseline_replica_results = {}\n",
    "\n",
    "for slide in slides: \n",
    "    baseline_replica_results[slide] = []\n",
    "    for replica in replicas: \n",
    "        baseline_plan = f\"plan_baseline_{slide}_{prio}\"\n",
    "        \n",
    "        total_loss = 0\n",
    "        for key in range(1, 101, 1):\n",
    "            oracle_filename = f\"{oracle_dir}/{key}.csv\"\n",
    "            \n",
    "            lp_filename = f\"{results_dir}/replica_{replica}/{baseline_plan}/{key}.csv\"\n",
    "            \n",
    "            baseline_filename = f\"{results_dir}/replica_{replica}/{baseline_plan}/{key}.csv\"\n",
    "            results = get_loss_per_key(baseline_filename, oracle_filename)\n",
    "            #print(results)\n",
    "            total_loss += results[\"loss\"]\n",
    "            \n",
    "        baseline_replica_results[slide].append(total_loss)\n",
    "    \n",
    "baseline_replica_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "print(replicas)\n",
    "x = 'Factor'\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    x: replicas, \n",
    "    **baseline_replica_results,\n",
    "})\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "tidy = df.melt(id_vars=x).rename(columns=str.title)\n",
    "seaborn.barplot(x=x, y='Value', hue='Variable', data=tidy, ax=ax1)\n",
    "seaborn.despine(fig)\n",
    "\n",
    "ax1.set(xlabel=\"Num Replicas\", ylabel=f'MASE Loss', title='Residual Estimate Loss for Time-Series Decomposition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd593565",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [(\"max_fits_1100\", 96), (\"max_fits_2100\", 48), (\"max_fits_4200\", 24), (\"max_fits_8400\", 12)]\n",
    "replicas = [1, 2]\n",
    "slides = [1, 6, 12, 18, 24, 48, 96, 168, 192, 336, 672]\n",
    "graph_results = {\"baseline\": [], \"optimized\": [], \"cost\": []}\n",
    "\n",
    "lp_replica_results = {}\n",
    "\n",
    "for plan, slide in experiments: \n",
    "    lp_replica_results[plan] = []\n",
    "    \n",
    "    for replica in replicas:\n",
    "        total_loss = 0\n",
    "        for key in range(1, 101, 1):\n",
    "            oracle_filename = f\"{oracle_dir}/{key}.csv\"\n",
    "            lp_filename = f\"{results_dir}/replica_{replica}/{plan}/{key}.csv\"\n",
    "            results = get_loss_per_key(lp_filename, oracle_filename)\n",
    "            total_loss += results[\"loss\"]\n",
    "            \n",
    "        lp_replica_results[plan].append(total_loss)\n",
    "        print(plan, total_loss)\n",
    "    \n",
    "lp_replica_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_results = {1: [213.2200178532724, 150.7256273025718, 133.3349003094353],\n",
    " 6: [218.75801939773078, 156.0948132080653, 135.81574629721845],\n",
    " 12: [220.90611494937247, 159.05690147515068, 138.24448802117672],\n",
    " 18: [229.63341620779627, 163.1813146667572, 140.3471142793597],\n",
    " 24: [233.91725185369373, 164.71255155633278, 144.22561887879107],\n",
    " 48: [268.3977607679711, 184.14616983478135, 158.3310894771346],\n",
    " 96: [348.50466291276604, 229.46322062727472, 189.37872271737845],\n",
    " 168: [474.50432909190295, 319.6199513026192, 281.5650612571233],\n",
    " 192: [609.2301332698065, 399.7143084337964, 333.28670707646245],\n",
    " 336: [908.5841349053487, 728.1723528503993, 650.7431132687982],\n",
    " 672: [1848.5207568587812, 1612.2188363608043, 1489.8733845259228]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_results = {'max_fits_1100': [1893.9663657607266, 133.45026146609104, 117.59550187337948],\n",
    " 'max_fits_2100': [2875.0872626231935, 1447.6250864288265, 99.89538248542472],\n",
    " 'max_fits_4200': [3430.718917641645, 2591.967671743391, 95.01342291496671],\n",
    " 'max_fits_8400': [3586.4346343021443, 3006.052341175111, 93.57666588051953]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46b74a",
   "metadata": {},
   "source": [
    "## Select best from baseline/policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicas = [1, 2]\n",
    "results = {\"baseline\": [], \"policy\": []}\n",
    "for i in range(len(replicas)): \n",
    "    \n",
    "    best_baseline = None\n",
    "    for key in baseline_replica_results.keys(): \n",
    "        if best_baseline is None or baseline_replica_results[key][i] <= best_baseline: \n",
    "            best_baseline = baseline_replica_results[key][i]\n",
    "    results[\"baseline\"].append(best_baseline)\n",
    "    \n",
    "    best_baseline = None\n",
    "    for key in lp_replica_results.keys(): \n",
    "        if best_baseline is None or lp_replica_results[key][i] <= best_baseline: \n",
    "            best_baseline = lp_replica_results[key][i]\n",
    "    results[\"policy\"].append(best_baseline)\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47fce1e",
   "metadata": {},
   "source": [
    "## Plot Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1678043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "x = 'Factor'\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    x: replicas, \n",
    "    **results,\n",
    "})\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "tidy = df.melt(id_vars=x).rename(columns=str.title)\n",
    "seaborn.barplot(x=x, y='Value', hue='Variable', data=tidy, ax=ax1)\n",
    "seaborn.despine(fig)\n",
    "\n",
    "ax1.set(xlabel=\"Num Replicas\", ylabel=f'MASE Loss', title='Residual Estimate Loss for Time-Series Decomposition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bccc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
