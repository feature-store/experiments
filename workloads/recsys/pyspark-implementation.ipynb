{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819fa848",
   "metadata": {},
   "source": [
    "- splitting up users (50% of user 1 rating, 50% of user 2 rating)\n",
    "\n",
    "\n",
    "1) reassign timestamps arbitrarily \n",
    "2) for each user, take first 1/2 --> als, 1/2 --> stream/test\n",
    "\n",
    "1) pretraining movie vectors --> \n",
    "\n",
    "does using pyspark still count --> yes, keep ML simple for system paper\n",
    "maybe point query slows down enough? --> maybe a bad thing\n",
    "\n",
    "1) verify model that works \n",
    "2) verify updating user embeddings helps predictions\n",
    "3) can figure out slowing down later\n",
    "4) are we prioritizng larger workloads (1M instead of 100k) --> \n",
    "\n",
    "push to main instead of branch (movie-lens/als)\n",
    "- fix up joey als\n",
    "\n",
    "undergrad onboarding\n",
    "- open source side\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb090da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d43e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/homebrew/Caskroom/miniconda/base/envs/myenv/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/10 01:44:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master('local').appName('als').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60319a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/Users/amitnarang/movielens/5050/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0389e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,IntegerType, StructType,StringType\n",
    "newDF=[StructField('user_id',IntegerType(),True),\n",
    "       StructField('movie_id',IntegerType(),True),\n",
    "       StructField('rating',IntegerType(),True),\n",
    "       StructField('timestamp',IntegerType(),True),\n",
    "       ]  \n",
    "finalStruct=StructType(fields=newDF)\n",
    "ratings = spark.read.csv(dir_path + \"als_data.csv\", schema=finalStruct, header=True)\n",
    "test_data = spark.read.csv(dir_path + \"stream_data.csv\", schema=finalStruct, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ebfa356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+\n",
      "|user_id|movie_id|rating|timestamp|\n",
      "+-------+--------+------+---------+\n",
      "|    259|     255|     4|874724710|\n",
      "|    259|     286|     4|874724727|\n",
      "|    259|     298|     4|874724754|\n",
      "|    259|     185|     4|874724781|\n",
      "|    259|     173|     4|874724843|\n",
      "|    259|     772|     4|874724882|\n",
      "|    259|     108|     4|874724882|\n",
      "|    259|     288|     3|874724905|\n",
      "|    259|     928|     4|874724937|\n",
      "|    259|     117|     4|874724988|\n",
      "|    259|     200|     4|874725081|\n",
      "|    259|     405|     3|874725120|\n",
      "|    259|    1074|     3|874725264|\n",
      "|    259|     176|     4|874725386|\n",
      "|    259|     210|     4|874725485|\n",
      "|    259|     357|     5|874725485|\n",
      "|    851|     687|     2|874728168|\n",
      "|    851|     696|     3|874728338|\n",
      "|    851|     284|     3|874728338|\n",
      "|    851|     295|     5|874728370|\n",
      "+-------+--------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4c6f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+\n",
      "|user_id|movie_id|rating|timestamp|\n",
      "+-------+--------+------+---------+\n",
      "|      1|     176|     5|876892468|\n",
      "|      1|     231|     1|876893031|\n",
      "|      1|      91|     5|876892636|\n",
      "|      1|     193|     4|876892654|\n",
      "|      1|     217|     3|876892676|\n",
      "|      1|     177|     5|876892701|\n",
      "|      1|     216|     5|876892701|\n",
      "|      1|     194|     4|876892743|\n",
      "|      1|      73|     3|876892774|\n",
      "|      1|      59|     5|876892817|\n",
      "|      1|      41|     2|876892818|\n",
      "|      1|     133|     4|876892818|\n",
      "|      1|     195|     5|876892855|\n",
      "|      1|     170|     5|876892856|\n",
      "|      1|     218|     3|876892856|\n",
      "|      1|     213|     2|876892896|\n",
      "|      1|     157|     4|876892918|\n",
      "|      1|     223|     5|876892918|\n",
      "|      1|      27|     2|876892946|\n",
      "|      1|     227|     4|876892946|\n",
      "+-------+--------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.sort('user_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b748f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa047985",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "         userCol=\"user_id\", \n",
    "         itemCol=\"movie_id\",\n",
    "         ratingCol=\"rating\", \n",
    "         nonnegative = True, \n",
    "         implicitPrefs = False,\n",
    "         coldStartStrategy=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "586fa3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf349380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [150]) \\\n",
    "            .addGrid(als.regParam, [.1]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcab4709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  1\n"
     ]
    }
   ],
   "source": [
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "           metricName=\"rmse\", \n",
    "           labelCol=\"rating\", \n",
    "           predictionCol=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3418b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f36d6b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1999:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0037441470066895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(ratings)\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel\n",
    "# View the predictions\n",
    "test_predictions = best_model.transform(test_data)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61ff473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Best Model**\n",
      "  Rank: 150\n",
      "  MaxIter: 10\n",
      "  RegParam: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"**Best Model**\")\n",
    "# Print \"Rank\"\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "366c8930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2023:===============================================>     (90 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|      1|[{408, 4.934828},...|\n",
      "|      2|[{1449, 4.4305215...|\n",
      "|      3|[{344, 3.3770661}...|\n",
      "|      4|[{1131, 5.6823254...|\n",
      "|      5|[{1142, 4.613391}...|\n",
      "|      6|[{134, 4.254445},...|\n",
      "|      7|[{612, 4.9064746}...|\n",
      "|      8|[{127, 4.917586},...|\n",
      "|      9|[{1131, 4.366975}...|\n",
      "|     10|[{1449, 4.9595895...|\n",
      "|     11|[{718, 4.5692844}...|\n",
      "|     12|[{318, 4.9410357}...|\n",
      "|     13|[{851, 4.9060307}...|\n",
      "|     14|[{408, 5.027333},...|\n",
      "|     15|[{459, 4.47861}, ...|\n",
      "|     16|[{136, 4.944799},...|\n",
      "|     17|[{483, 4.0543947}...|\n",
      "|     18|[{170, 4.6695433}...|\n",
      "|     19|[{8, 4.571447}, {...|\n",
      "|     20|[{916, 4.141518},...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2023:====================================================>(99 + 1) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommendations = best_model.recommendForAllUsers(5)\n",
    "recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11cc7795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2072:================================================>    (92 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "|user_id|movie_id|   rating|\n",
      "+-------+--------+---------+\n",
      "|      1|     408| 4.934828|\n",
      "|      1|    1142| 4.832595|\n",
      "|      1|     169|4.7931576|\n",
      "|      1|     114|4.7699485|\n",
      "|      1|      50| 4.749361|\n",
      "|      2|    1449|4.4305215|\n",
      "|      2|     275|4.2517853|\n",
      "|      2|     190|4.2478666|\n",
      "|      2|     483| 4.224928|\n",
      "|      2|     478| 4.186218|\n",
      "+-------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "nrecommendations = recommendations\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('user_id', col(\"rec_exp.movie_id\"), col(\"rec_exp.rating\"))\n",
    "nrecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5323285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2147:===============================>                     (60 + 2) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "|user_id|movie_id|   rating|\n",
      "+-------+--------+---------+\n",
      "|    100|     313|4.2239876|\n",
      "|    100|     916|3.9103782|\n",
      "|    100|     318|3.8815289|\n",
      "|    100|      22|3.8615365|\n",
      "|    100|     900|3.8392437|\n",
      "+-------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2147:==============================================>      (87 + 1) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nrecommendations.filter('user_id = 100').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7e39cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.itemFactors.toPandas().sort_values('id').to_csv(dir_path + 'movie_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed3ca8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.userFactors.toPandas().sort_values('id').to_csv(dir_path + 'user_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "746a2bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = best_model.transform(test_data)\n",
    "evaluator = RegressionEvaluator().setMetricName(\"rmse\").setLabelCol(\"rating\").setPredictionCol(\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9d5f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0037441470066895\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
